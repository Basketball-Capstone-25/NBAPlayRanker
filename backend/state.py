"""backend/state.py

This module holds **long-lived, cached state** for the FastAPI backend.

Why this exists:
- FastAPI handles multiple requests (potentially from multiple users) at the same time.
- We do NOT want to re-load a large CSV or re-build tables on every request.
- Instead, we load the dataset and prepare baseline tables ONE time at startup,
  then reuse them for:
    1) Data Explorer (raw/cleaned data preview + export)
    2) Baseline recommender (explainable ranking)
    3) Context + ML recommender (AI use case)

Important architectural note:
- FastAPI is still *stateless per request*.
- This cache is simply an in-memory optimization (standard practice).
- If you run multiple workers (e.g., uvicorn --workers 2), each worker process
  will have its own in-memory cache (also standard).
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional

import pandas as pd

from baseline_recommender import BaselineRecommender


# ------------------------------------------------------------
# 1) File locations (relative to backend/)
# ------------------------------------------------------------

DATA_DIR = Path(__file__).parent / "data"

# Raw Synergy snapshot pulled via R/hoopR script:
# backend/data/etl/build_synergy_dataset.R
SYNERGY_CSV_PATH = DATA_DIR / "synergy_playtypes_2019_2025_players.csv"

# Precomputed ML predictions (generated by backend/ml_models.py):
# Contains: SEASON, TEAM_ABBREVIATION, PLAY_TYPE, PPP_ML
ML_PRED_PATH = DATA_DIR / "ml_offense_ppp_predictions.csv"


# ------------------------------------------------------------
# 2) Global cached objects
# ------------------------------------------------------------

# Baseline recommender loads the Synergy snapshot and prepares:
# - team_df: cleaned + aggregated team-level rows
# - league_df: league averages for shrinkage baselines
baseline_rec = BaselineRecommender(str(SYNERGY_CSV_PATH))

# ML predictions are optional (but required for the Context+ML page).
# If missing, the context endpoint will throw a helpful error telling you to regenerate.
ml_pred_df: Optional[pd.DataFrame] = None
if ML_PRED_PATH.exists():
    ml_pred_df = pd.read_csv(ML_PRED_PATH)

    # Basic sanity checks (defensive programming).
    required_cols = {"SEASON", "TEAM_ABBREVIATION", "PLAY_TYPE", "PPP_ML"}
    missing = required_cols - set(ml_pred_df.columns)
    if missing:
        raise ValueError(
            f"ml_offense_ppp_predictions.csv is missing columns: {sorted(missing)}"
        )


# ------------------------------------------------------------
# 3) Small "meta" helpers used by the frontend
# ------------------------------------------------------------

def get_meta_options() -> Dict[str, Any]:
    """Dropdown options for the UI.

    We generate these dynamically from the dataset so the frontend does not need
    hard-coded lists.
    """

    team_df = baseline_rec.team_df

    seasons = sorted(team_df["SEASON"].dropna().unique().tolist())
    teams = sorted(team_df["TEAM_ABBREVIATION"].dropna().unique().tolist())
    play_types = sorted(team_df["PLAY_TYPE"].dropna().unique().tolist())

    # Optional: a mapping to display full names in the UI if desired.
    team_name_map = (
        team_df[["TEAM_ABBREVIATION", "TEAM_NAME"]]
        .dropna()
        .drop_duplicates()
        .set_index("TEAM_ABBREVIATION")["TEAM_NAME"]
        .to_dict()
    )

    return {
        "seasons": seasons,
        "teams": teams,
        "teamNames": team_name_map,
        "playTypes": play_types,
        "sides": ["offense", "defense"],
        "hasMlPredictions": ml_pred_df is not None,
    }


def get_pipeline_info() -> Dict[str, Any]:
    """Committee-friendly summary of the pipeline (what data, how itâ€™s built)."""

    return {
        "dataSource": "NBA Synergy play-type stats pulled via hoopR::nba_synergyplaytypes (public NBA endpoints)",
        "etl": {
            "tool": "R",
            "script": "backend/data/etl/build_synergy_dataset.R",
            "output": "backend/data/synergy_playtypes_2019_2025_players.csv",
            "notes": [
                "Pulls Synergy play-type splits by season/play type/side.",
                "Caches chunk CSVs locally to avoid hammering the endpoint.",
                "Builds one combined snapshot file used by the app.",
            ],
        },
        "cleaning_and_aggregation": [
            "Convert numeric columns to numeric types (NaN on bad values).",
            "Aggregate player rows into team-level rows using possession-weighted averages.",
            "Recompute team-level POSS_PCT from team-level possessions (prevents double-counting).",
            "Add reliability weights based on possessions to reduce small-sample noise (shrinkage).",
        ],
        "modeling": [
            "Baseline recommender: explainable shrinkage + weighted blend vs opponent defense.",
            "Context+ML recommender: ML-predicted offensive PPP blended with opponent defense + small context adjustments.",
        ],
    }


def get_baseline_formula() -> Dict[str, Any]:
    """Baseline formula + definitions so it can be shown in the UI."""

    return {
        "formula": "PPP_PRED = w_off * PPP_OFF_SHRUNK + w_def * PPP_DEF_SHRUNK",
        "defaults": {"w_off": 0.7, "w_def": 0.3},
        "definitions": {
            "PPP_OFF_SHRUNK": "Our offense PPP shrunk toward league PPP (reduces noise when possessions are low).",
            "PPP_DEF_SHRUNK": "Opponent allowed PPP shrunk toward league PPP (reduces noise).",
            "w_off": "Weight on our offensive history for that play type.",
            "w_def": "Weight on opponent defensive tendencies for that play type.",
        },
        "whyShrinkage": (
            "Low-sample play types can look misleading. Shrinkage prevents overconfidence "
            "by pulling extreme values toward the league average."
        ),
    }


def get_data_audit() -> Dict[str, Any]:
    """Lightweight dataset audit for credibility (optional endpoint can expose this).

    This is intentionally simple and fast.
    """

    df = baseline_rec.team_df

    return {
        "rows_team_level": int(df.shape[0]),
        "seasons": sorted(df["SEASON"].dropna().unique().tolist()),
        "teams": sorted(df["TEAM_ABBREVIATION"].dropna().unique().tolist()),
        "play_types": sorted(df["PLAY_TYPE"].dropna().unique().tolist()),
        "missing": {
            "PPP": int(df["PPP"].isna().sum()) if "PPP" in df.columns else None,
            "POSS": int(df["POSS"].isna().sum()) if "POSS" in df.columns else None,
        },
        "ml_predictions_loaded": ml_pred_df is not None,
        "paths": {
            "synergy_csv": str(SYNERGY_CSV_PATH),
            "ml_pred_csv": str(ML_PRED_PATH),
        },
    }
